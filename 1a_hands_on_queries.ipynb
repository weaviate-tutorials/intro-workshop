{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7d66c4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-on with Weaviate: Queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a17ff9d6",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/weaviate-tutorials/intro-workshop/blob/main/1a_hands_on_queries.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef121d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Colab\n",
    "# !pip install -U weaviate-client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "081fda50",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Instantiate Weaviate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a4f88",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "client = weaviate.Client(\n",
    "    \"https://edu-demo.weaviate.network\",\n",
    "    auth_client_secret=weaviate.AuthApiKey(\"learn-weaviate\"),\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "595b113b",
   "metadata": {},
   "source": [
    "### Inspect database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf771f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get schema\n",
    "schema = client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the schema look like?\n",
    "schema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "383cdead",
   "metadata": {},
   "source": [
    "#### Note: Weaviate data structures:\n",
    "\n",
    "- `class`: A collection of objects (like a SQL table)\n",
    "- `properties`: Object properties (like a SQL column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What classes are in the instance?\n",
    "c_names = [c[\"class\"] for c in schema[\"classes\"]]\n",
    "c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39565c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect a particular class\n",
    "class_schema = client.schema.get('WineReview')\n",
    "class_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a661b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What properties are in a particular class?\n",
    "p_names = [p[\"name\"] for p in class_schema[\"properties\"]]\n",
    "p_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53d0baaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Search - basic\n",
    "\n",
    "### Fetch items from Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fa9a8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Get query\n",
    "# Let's use the property names from above\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", p_names)\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b8a5e95",
   "metadata": {},
   "source": [
    "**Quiz**: In what order do these objects come from?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57c4153c",
   "metadata": {},
   "source": [
    "### Specify the fetched properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29bb7b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Modify properties to be fetched\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\"])\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac763b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw GraphQL query\n",
    "\n",
    "gql_query = \"\"\"\n",
    "{\n",
    "    Get {\n",
    "        WineReview (limit: 3) {\n",
    "            title\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "gql_response = (\n",
    "    client.query.raw(gql_query)\n",
    ")\n",
    "gql_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f58cbb25",
   "metadata": {},
   "source": [
    "### Fetch additional properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858f988",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Fetch object ID / vector\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\"])\n",
    "    .with_additional([\"id\", \"vector\"])\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bfdf2b4",
   "metadata": {},
   "source": [
    "#### Fetch cross-referenced properties\n",
    "\n",
    "Cross-references are like relationships in SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch JeopardyQuestion item\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"JeopardyQuestion\", [\"question\" ,\"answer\"])\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show `JeopardyQuestion` schema\n",
    "client.schema.get(\"JeopardyQuestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a532ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show x-referenced class schema\n",
    "client.schema.get(\"JeopardyCategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch JeopardyQuestion item\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"JeopardyQuestion\", [\"question\" ,\"answer\", \"hasCategory {...on JeopardyCategory {title}}\"])\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5b2e6a3",
   "metadata": {},
   "source": [
    "## Similarity-based searches\n",
    "\n",
    "### NearText search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearText query - \"very fancy wine\"?\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_text({\n",
    "        \"concepts\": [\n",
    "            \"very fancy wine\"\n",
    "        ]\n",
    "    })\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ac934f7",
   "metadata": {},
   "source": [
    "### NearObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearObject query - first, grab an object ID\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_text({\n",
    "        \"concepts\": [\n",
    "            \"very fancy wine\"\n",
    "        ]\n",
    "    })\n",
    "    .with_additional(\"id\")\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4480517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearObject query - use that ID to run a search\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_object({\n",
    "        \"id\": \"f6da868f-9044-5b4d-87dd-21e1ffffbbf1\"\n",
    "    })\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6846b80f",
   "metadata": {},
   "source": [
    "### NearVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a vector from OpenAI\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_APIKEY\"]\n",
    "resp = openai.Embedding.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=\"Argentinian wine that goes well with fish\"\n",
    ")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = resp[\"data\"][0][\"embedding\"]\n",
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearVector query - use the vector to run a search\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_vector({\n",
    "        \"vector\": emb\n",
    "    })\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69ef8529",
   "metadata": {},
   "source": [
    "**Discussion**: What's going on under the hood?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f452946",
   "metadata": {},
   "source": [
    "![image](https://weaviate.io/assets/images/search-conceptual-dark-315f1e31d9008ce661031c31c1273bd2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6854464c",
   "metadata": {},
   "source": [
    "### Get distances to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79309ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch distances in the results\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_vector({\n",
    "        \"vector\": emb\n",
    "    })\n",
    "    .with_additional(\"distance\")\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bc9196f",
   "metadata": {},
   "source": [
    "### Modify thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfe5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a distance threshold\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_near_vector({\n",
    "        \"vector\": emb,\n",
    "        \"distance\": 0.14\n",
    "    })\n",
    "    .with_additional(\"distance\")\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17733ee3",
   "metadata": {},
   "source": [
    "**Discussion**: Why do we need thresholds / limits?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f184aa4e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Keyword (BM25) searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56395a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a keyword search for \"apple\"\n",
    "\n",
    "response = (\n",
    "    client.query.get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_bm25(\"apple\")\n",
    "    .with_additional(\"score\")\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56a81fc3",
   "metadata": {},
   "source": [
    "**Discussion**: How do keyword (BM25) searches work?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23b84a29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hybrid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc135e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a hybrid search for \"white wine easy drink\"\n",
    "\n",
    "response = (\n",
    "    client.query.get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_hybrid(\"white wine easy drink\")\n",
    "    .with_additional(\"score\")\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f30574c",
   "metadata": {},
   "source": [
    "**Discussion**: How do hybrid searches work?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "add6bb74",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conditional (`where`) Filters\n",
    "\n",
    "### Single filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single filter with price\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_vector({\n",
    "        \"vector\": emb\n",
    "    })\n",
    "    .with_where({\n",
    "        \"path\": [\"price\"],\n",
    "        \"operator\": \"GreaterThan\",\n",
    "        \"valueNumber\": 10\n",
    "    })\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21d0a08d",
   "metadata": {},
   "source": [
    "#### Filter by partial matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter with partial string\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\", \"review_body\", \"country\"])\n",
    "    .with_limit(3)\n",
    "    .with_near_vector({\n",
    "        \"vector\": emb\n",
    "    })\n",
    "    .with_where({\n",
    "        \"path\": [\"review_body\"],\n",
    "        \"operator\": \"Like\",\n",
    "        \"valueText\": \"*citrus*\"\n",
    "    })\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a6ac1d7",
   "metadata": {},
   "source": [
    "#### Filter by cross-references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter with cross-ref property (look for *history*)\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"JeopardyQuestion\", [\"question\", \"answer\", \"hasCategory {...on JeopardyCategory {title}}\"])\n",
    "    .with_limit(5)\n",
    "    .with_where({\n",
    "        \"path\": [\"hasCategory\", \"JeopardyCategory\", \"title\"],\n",
    "        \"operator\": \"Like\",\n",
    "        \"valueText\": \"*histor*\"\n",
    "    })\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bc2b2b6",
   "metadata": {},
   "source": [
    "### Nested filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567805d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter with nested filters\n",
    "# `points` greater than 1000 or Like *history*\n",
    "where_filter = {\n",
    "    \"operator\": \"Or\",\n",
    "    \"operands\": [\n",
    "        {\n",
    "            \"path\": [\"hasCategory\", \"JeopardyCategory\", \"title\"],\n",
    "            \"operator\": \"Like\",\n",
    "            \"valueText\": \"*history*\"\n",
    "        },   \n",
    "        {\n",
    "            \"path\": [\"points\"],\n",
    "            \"operator\": \"GreaterThan\",\n",
    "            \"valueInt\": 1000\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"JeopardyQuestion\", [\"question\", \"answer\", \"points\", \"hasCategory {...on JeopardyCategory {title}}\"])\n",
    "    .with_limit(5)\n",
    "    .with_where(where_filter)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35aaf7e0",
   "metadata": {},
   "source": [
    "## Generative searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252850df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearText with Generative\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WikiArticle\", [\"title\"])\n",
    "    .with_limit(1)\n",
    "    .with_near_text({\n",
    "        \"concepts\": [\n",
    "            \"australia\"\n",
    "        ]\n",
    "    })\n",
    "    .with_generate(\n",
    "        single_prompt=\"Summarize this article {wiki_summary}\"\n",
    "    )\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19726bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get grouped data\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"WineReview\", [\"title\"])\n",
    "    .with_limit(10)\n",
    "    .with_near_text({\n",
    "        \"concepts\": [\n",
    "            \"dessert wine\"\n",
    "        ]\n",
    "    })\n",
    "    .with_generate(\n",
    "        grouped_task=\"Based on these reviews, what should you look for in a dessert wine? Provide three bullet points\"\n",
    "    )\n",
    "    .do()\n",
    ")\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
